{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSA Evaluation Metrics\n",
    "###  Most common Evaluation Metrics for TSA/Regression Analysis:\n",
    "\n",
    "@joydeepubuntu's [Blog](https://medium.com/@joydeepubuntu/common-metrics-for-time-series-analysis-f3ca4b29fe42) <br>\n",
    "Rob Hyndmans's [Suggestions](https://www.sciencedirect.com/science/article/abs/pii/S0169207006000239) <br>\n",
    "                                                                                                          \n",
    "- $y_{i}$ : **real value** of the test data\n",
    "- $\\hat y_{i}$: **Predicted value** from our forecast\n",
    "<br>`And Residual is how far the actual value is from the predicted value`, i.e. error in a prediciton\n",
    "> here, $y_{i}-\\hat y_{i}$ is the ***residual component***\n",
    "\n",
    "<br>`-ve residual value = predicted value fall below the actual value`\n",
    "<br>`+ve residual value = predicted value falls above the actual value`\n",
    "\n",
    "1) <b> Mean Squared Error </b>: MAE misses on some large errors due to MEAN of rest of the values, thus MSE is more popular => \n",
    "$ \\frac{1}{n} \\sum_{i=1}^n (y_{i} - \\hat y_{i})^2 $\n",
    "\n",
    "```python\n",
    ">>> from sklearn.metrics import mean_squared_error\n",
    ">>> print(mean_squared_error(y_pred, y_true))\n",
    "0.375\n",
    "```\n",
    "<br>\n",
    "\n",
    "2) <b> Root Mean Squared Error </b>: Due to the square of residual values in MSE, units are also squared, i.e. $ Dollar^2, count of people^2,etc.$, thus\n",
    "<br>\n",
    "$\\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_{i} - \\hat y_{i})^2}$\n",
    "\n",
    "```python\n",
    ">>> from sklearn.metrics import mean_squared_error\n",
    ">>> mse=mean_squared_error(y_pred, y_true)\n",
    ">>> print(np.sqrt(rmse))\n",
    "0.06\n",
    "```\n",
    "<br>\n",
    "\n",
    "3) <b>Mean Absolute Error</b>:  Mean of the absolute value of errors => \n",
    "$ \\frac{1}{n} \\sum_{i=1}^n | y_{i} - \\hat y_{i} | $\n",
    "```python\n",
    ">>> from sklearn.metrics import mean_absolute_error\n",
    ">>> print(mean_absolute_error(y_true, y_pred))\n",
    "0.5\n",
    "\n",
    ">>> from sklearn.metrics import median_absolute_error\n",
    ">>> print(median_absolute_error(y_true, y_pred))\n",
    "0.5\n",
    "```\n",
    "<br>\n",
    "\n",
    "4) <b> Mean Absolute Percentage Error </b>: \n",
    "$ \\frac{1}{n} \\sum_{i=1}^n \\left\\lvert{\\frac{y_{i}-\\hat y}{y_{i}}}\\right\\rvert $ or \n",
    "$ \\frac{1}{n} \\sum_{i=1}^n \\left\\lvert{\\frac{Act_{i}- F_{i}}{Act_{i}}}\\right\\rvert $\n",
    "<br> \n",
    "MAPE doesn't has nay implementation in sci-kit learn, thus <br>\n",
    "\n",
    "```python\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "```\n",
    "<br>\n",
    "\n",
    "5) <b> Symmetric Mean Absolute Percentage Error </b>: \n",
    "SMAPE = $\\frac{100\\%}{n} \\sum_{t=1}^n \\frac{|F_{t}-A_{t}|}{(|A_{t}|+|F_{t}|)/2}$\n",
    "<br> \n",
    "SMAPE doesn't has nay implementation in sci-kit learn, thus <br>\n",
    "\n",
    "```python\n",
    "def smape(Act, Fcst):\n",
    "    smape_val = round(100/len(Act) * np.sum(2 * np.abs(Fcst - Act) / (np.abs(Act) + np.abs(Fcst))),2)\n",
    "    return smape_val\n",
    "```\n",
    "<b><i> Reason for divison by 2 in sMAPE is justified by [Spyros Makridakis](\"https://sci-hub.tw/10.1016/0169-2070(93)90079-3\")</i></b> <br>\n",
    "MAPE as an accuracy measure can be influenced by some problems:\t\n",
    "- Equal errors above the actual value result in a greater APE (Absolute Percentage Error) than those below the actual value. For instance, when the actual value is 150 and the forecast is 100 (an error of 50) the APE(|(Act-Fcst/Act)|) is: 33%\n",
    "- However, when the actual is 100 and the forecast 150 the APE is 50%\n",
    "- This problem can be easily corrected by dividing the error (Act - Fcst) by the average of both Act and Fcst i.e.  (Act + Fcst)/2\n",
    "- The above formula will provide the APE of 40% in both cases\n",
    "\n",
    "<br>\n",
    "6) <b> $R^2$ </b>: Is a measure of how close each datapoint fits the regression line, So it tells us, how well the regression line predicts the actual value\n",
    "\n",
    "```python\n",
    ">>> from sklearn.metrics import r2_score\n",
    ">>> r2_score(y_true, y_pred)\n",
    "0.9486081370449679\n",
    "```\n",
    "\n",
    "@joydeepubuntu's [Blog](https://medium.com/@joydeepubuntu/common-metrics-for-time-series-analysis-f3ca4b29fe42) <br>\n",
    "Rob Hyndmans's [Suggestions](https://www.sciencedirect.com/science/article/abs/pii/S0169207006000239) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs_fit_2020_07_29_19_35_35\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "print(\"logs_fit_\" + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
