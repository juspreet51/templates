{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"GOLD\"><b><ins>Recurrent Neural Network</ins></b></font>\n",
    "RNN are specifically designed to work with sequential data,\n",
    "- Time Series Data\n",
    "- Audio\n",
    "- Sentences\n",
    "- Music\n",
    "- Car Trajectories\n",
    "\n",
    "In TS, if current data is <font color=\"green\">[1,2,3,4,5,6]</font> and next data is <font color=\"green\">[2,3,4,5,6,7]</font>, then RNN will help in telling the next sequence could be <font color=\"green\">[3,4,5,6,7,8]</font>\n",
    "\n",
    "___Similarly, sales for next day___\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"purple\"><b><ins>Feed-Forward Network V/S RNN Network</ins></b></font>\n",
    "<div style=\"overflow: hidden;justify-content:space-around;\">\n",
    "    \n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/feed_forward_network.PNG\" style=width:300px>\n",
    "</div>\n",
    "\n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/rnn_network.PNG\" style=width:300px>\n",
    "</div>\n",
    "    \n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/rnn_network_01.PNG\" style=width:300px>\n",
    "</div>\n",
    "</div>    \n",
    "\n",
    "<br><br><font color=\"green\">__Memory Cells__</font>\n",
    "Cells which are function of I/P from previous time steps are called as Memory Cells\n",
    "<br> Since the output of the neurons at timestamp _t_ is input to neurons at timestamp _t+1_, memory of the past time is being supplied to future timestamp nodes\n",
    "<br> This is how it learns about the historical information and has a memorising way of working\n",
    "\n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/rnn_network_02.PNG\" style=width:400px>\n",
    "</div>\n",
    "\n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/RNN_Network_03.PNG\" style=width:400px>\n",
    "</div>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"purple\"><b><ins>Types of RNN</ins></b></font>\n",
    "\n",
    "- <font color=\"green\">Sequence to Sequence</font>, e.g. dily sales data and then next day sales prediction, or a happy relationship<br>\n",
    "\n",
    "- <font color=\"green\">Sequence2VectorRNN</font>, e.g. Sentiment Analysis, or a inbox of a pretty girl, everyone is texting 1 girl only<br>\n",
    "\n",
    "- <font color=\"green\">Vector2SequenceRNN</font>, e.g. Predective Texts, or a inbox of an irritating boy, he is texting everyone<br>\n",
    "\n",
    "<div style=\"overflow: hidden;justify-content:space-around;\">\n",
    "    \n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/Sequence2SequenceRNN.PNG\" style=width:300px>\n",
    "</div>\n",
    "\n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/Sequence2VEctorRNN.PNG\" style=width:300px>\n",
    "</div>\n",
    "    \n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/Vector2SequenceRNN.PNG\" style=width:300px>\n",
    "</div>\n",
    "</div> \n",
    "\n",
    "\n",
    "## <font color=\"orange\"><b>However, RNN tends to forget the past knowledge, and thus we need a Long-Term memory cells</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"orange\"><b><font color=\"green\">LSTM</font> was created to address this issue</b></font>\n",
    "\n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/LSTM_00.PNG\" style=width:500px>\n",
    "</div>\n",
    "\n",
    "___\n",
    "\n",
    "t — time step <br>\n",
    "X — input <br>\n",
    "h — hidden state <br>\n",
    "C — cell state <br>\n",
    "length of X — size/dimension of input <br>\n",
    "length of h — no. of hidden units <br>\n",
    "\n",
    "<img src=\"./imgs/raimi_rnn_01.PNG\" style=width:700px>\n",
    "\n",
    "<img src=\"./imgs/raimi_rnn_02.PNG\" style=width:700px>\n",
    "\n",
    "<img src=\"./imgs/raimi_rnn_03.PNG\" style=width:700px>\n",
    "\n",
    "### _awesome graphics' credits_ [Raimi Karim](https://towardsdatascience.com/@remykarem)\n",
    "\n",
    "### <font color=\"green\">1) Forget Gate Layer:</font> </b> A sigmoid layer which helps in discarding the information we don't wish to carry to cell state\n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/LSTM_01.PNG\" style=width:500px>\n",
    "</div>\n",
    "\n",
    "### <font color=\"green\">2) What information to store in the cell state:</font> </b> A combination of sigmoid and Hyperbolic Tangent layer which helps in keeping the information we wish to carry to cell state\n",
    "__2.1) Input Gate Layer(i<sub>t</sub>):__ = $σ(W_{i}.[h_{t-1}x_{t}]+b_{i})$ <br>\n",
    "__2.2) New Candidate Value:__ $\\tilde{C}_{t} = tanh(W_{C}.[h_{t-1}x_{t}]+b_{C})$ \n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/LSTM_02.PNG\" style=width:500px>\n",
    "</div>\n",
    "\n",
    "\n",
    "### <font color=\"green\">3) Update the old cell state to new cell state:</font></b> $f_{t} informs what we want to forger and i_{t}$ knows what to informs what we wish to store, thus <br>\n",
    "> $C_{t} = f_{t}*C_{t-1} + i_{t}*\\tilde{C}_{t}$\n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/LSTM_03.PNG\" style=width:500px>\n",
    "</div>\n",
    "\n",
    "### <font color=\"green\">4) Deciding O/P for $h_{t}$:</font> </b> $f_{t} informs what we want to forger and i_{t}$ knows what to informs what we wish to store, thus <br>\n",
    "> $C_{t} = f_{t}*C_{t-1} + i_{t}*\\tilde{C}_{t}$\n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/LSTM_04.PNG\" style=width:500px>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"gold\"><b>Variations of LSTMs</b></font>\n",
    "\n",
    "### Peep-Hole LSTMs: It allows $f_{t}, i_{t}$ and $o_{t}$ to have a peek at the previous cell states, i.e. $C_{t-1}$\n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/LSTM_05.PNG\" style=width:500px>\n",
    "</div>\n",
    "\n",
    "### Gated Recurrent Neural Networks: Combines the forget and i/p gate to a single gate called Update Gate\n",
    "<div class=\"\" style=\"display: inline-block;\">\n",
    "    <img src=\"./imgs/LSTM_06.PNG\" style=width:500px>\n",
    "</div>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
